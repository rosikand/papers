# Papers



| Paper | Date Published | Categories |
|-------|------|----------|
| The Llama 3 Herd of Models ([pdf](papers/fall-2024/the-llama-3-herd-of-models-08-15-2024.pdf), [notes](notes/the-llama-3-herd-of-models.md)) | 2024-08-15 | Large Language Models, Foundation Models |



## ...

Reasoning:

- CoT
- Stream of Search (SoS): Learning to Search in Language

Scaling inference-time compute:

- Snell


Interesting neurips 2024 papers:

- MARPLE: A Benchmark for Long-Horizon Inference
- Test-Time Debiasing of Vision-Language Embeddings
- Toward Efficient Inference for Mixtures of Experts
- QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs
- MoVA: Adapting Mixture of Vision Experts to Multimodal Context
- Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation
- Kraken: Inherently Parallel Transformers For Efficient Multi-Device Inference
- DEX: Data Channel Extension for Efficient CNN Inference on Tiny AI Accelerators
- KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization
- NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention
- MInference: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention
- LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models
- Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference
- KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization
- SpecExec: Massively Parallel Speculative Decoding For Interactive LLM Inference on Consumer Devices
- Initialization is Critical to Whether Transformers Fit Composite Functions by Inference or Memorizing
- Frustratingly Easy Test-Time Adaptation of Vision-Language Models
- L-TTA: Lightweight Test-Time Adaptation Using a Versatile Stem Layer
- Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models
- TinyTTA: Efficient Test-time Adaptation via Early-exit Ensembles on Edge Devices
- Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery
